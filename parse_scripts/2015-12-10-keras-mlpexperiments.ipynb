{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fenparsev4 import *\n",
    "from pybrain.datasets import ClassificationDataSet\n",
    "from pybrain.supervised.trainers import BackpropTrainer\n",
    "from pybrain.tools.shortcuts import buildNetwork\n",
    "from pybrain.structure.modules import TanhLayer\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import os\n",
    "from __future__ import print_function\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizializing read of 75 files...\n",
      "Reading...done\n",
      "Converting to list...done\n",
      "Splitting data...done\n"
     ]
    }
   ],
   "source": [
    "#most important part\n",
    "def fries_ready():\n",
    "    os.system('say your fries are done')\n",
    "    \n",
    "def write(str):\n",
    "    sys.stdout.write('\\r' + str)\n",
    "    sys.stdout.flush()\n",
    "    \n",
    "def writeln(str):\n",
    "    sys.stdout.write(str)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "num_files = 75\n",
    "filename_prefix='/media/drive/storage/csv_input/2015-12-08_112mil'\n",
    "filename_suffix_range=range(1,num_files + 1)\n",
    "debug=True\n",
    "    \n",
    "#read in csv\n",
    "df = pd.DataFrame()\n",
    "writeln(\"Inizializing read of %d files...\\n\" % (num_files))\n",
    "for i in filename_suffix_range:\n",
    "    if debug: write(\"Reading...%d/%d\" % (i, num_files))\n",
    "    df = df.append(pd.read_csv(filename_prefix + str(i)))\n",
    "write(\"Reading...done\\n\")\n",
    "#clean columns\n",
    "df['y'] = df['y'].astype(int)\n",
    "if debug: writeln(\"Converting to list...\")\n",
    "df['x'] = df['x'] = df.loc[:, 'x'].apply(lambda x: [1 if '1' == a else 0 for a in x.split(', ')])\n",
    "length = df.shape[0]\n",
    "df = df.set_index([range(0,length)])\n",
    "writeln(\"done\\nShuffling data...\")\n",
    "df = df.reindex(np.random.permutation(df.index))\n",
    "writeln(\"done\")\n",
    "write(\"Splitting data...\")\n",
    "split = df.shape[0] * 4 / 5\n",
    "all_train = df.iloc[:split, :]\n",
    "all_test = df.iloc[split:, :]\n",
    "writeln(\"done\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building y labels\n",
      "converting X_train and X_test to nparrays\n",
      "converting y labels to categorical\n"
     ]
    }
   ],
   "source": [
    "(X_train, Y_train, X_test, Y_test) = build_dataset(all_train, all_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#takes in full dataframe and converts to usable dataset\n",
    "def build_dataset(all_train, all_test, nb_classes=2, debug=True):\n",
    "    X_train = list(all_train['x'])\n",
    "    X_test = list(all_test['x'])\n",
    "    if debug: print(\"building y labels\")\n",
    "    y_train = [[1] if y == 1 else [0] for y in all_train['y']]\n",
    "    y_test = [1 if y == 1 else 0 for y in all_test['y']]\n",
    "    if debug: print(\"converting X_train and X_test to nparrays\")\n",
    "    X_train = np.array(X_train)\n",
    "    X_test = np.array(X_test)\n",
    "    if debug: print(\"converting y labels to categorical\")\n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    return (X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def buildMLP(activation='tanh',depth=3):\n",
    "    if depth < 2:\n",
    "        depth = 2\n",
    "    model = Sequential()\n",
    "    model.add(Dense(512, input_shape=(1536,)))\n",
    "    model.add(Activation('tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    for i in range(0, depth - 2):\n",
    "        model.add(Dense(512))\n",
    "        model.add(Activation('tanh'))\n",
    "        model.add(Dropout(0.2))\n",
    "       \n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    rms = RMSprop()\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=rms)\n",
    "    #print(model.to_json())\n",
    "    writeln(\"Model with depth %d built...\" % depth)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class KerasExperiment:\n",
    "    def __init__(self, model, X_train, Y_train, X_test, Y_test, epochs=5, verbose=True):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.Y_train = Y_train\n",
    "        self.X_test = X_test\n",
    "        self.Y_test = Y_test\n",
    "        self.nb_epoch = epochs\n",
    "\n",
    "    #adds specific piece confusion matrices to results dict d\n",
    "    def add_piece_specifics(d):\n",
    "        pass\n",
    "        \n",
    "    \n",
    "    def run_experiment(self):\n",
    "        self.model.fit(self.X_train, self.Y_train, nb_epoch=self.nb_epoch,\n",
    "                  show_accuracy=True, verbose=2,\n",
    "                  validation_data=(X_test, Y_test))\n",
    "        score = self.model.evaluate(X_test, Y_test,\n",
    "                               show_accuracy=True, verbose=0)\n",
    "    #    print(confusion_matrix(y_train, out))\n",
    "        #return pd.DataFrame({\"train_size\": self.train_df.shape[0], \n",
    "#                             \"train_white_count\" : sum([1 if a.isupper() else 0 for a in self.train_df['piece_moved']]),\n",
    "#                             \"confusion_matrix\" : [cm],\n",
    "#                             \"accuracy\": [(cm[0][0] + cm[1][1]) * 1.0 / (sum([sum(c) for c in cm]))]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building net of depth 2...Train on 584268 samples, validate on 146068 samples\n",
      "Epoch 1/5\n",
      "163s - loss: 0.6103 - acc: 0.6500 - val_loss: 0.6068 - val_acc: 0.6658\n"
     ]
    }
   ],
   "source": [
    "for i in range(2, 6):\n",
    "    writeln(\"Building net of depth %d...\\n\" % i)\n",
    "    net = buildMLP(i)\n",
    "    writeln(\"Running experiment:\")\n",
    "    e = KerasExperiment(net, X_train, Y_train, X_test, Y_test)\n",
    "    results_df = e.run_experiment()\n",
    "fries_ready()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>confusion_matrix</th>\n",
       "      <th>train_size</th>\n",
       "      <th>train_white_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.491254</td>\n",
       "      <td>[[674, 3], [695, 0]]</td>\n",
       "      <td>24584</td>\n",
       "      <td>24584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy      confusion_matrix  train_size  train_white_count\n",
       "0  0.491254  [[674, 3], [695, 0]]       24584              24584"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>125</td>\n",
       "      <td>119</td>\n",
       "      <td>244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119</td>\n",
       "      <td>137</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>244</td>\n",
       "      <td>256</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted    0    1  All\n",
       "True                    \n",
       "0          125  119  244\n",
       "1          119  137  256\n",
       "All        244  256  500"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_true = pd.Series(y_test)\n",
    "y_pred = pd.Series(y_pred)\n",
    "pd.crosstab(y_true, y_pred, rownames=['True'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p\n",
      "[[36 20]\n",
      " [29 16]]\n",
      "0.356435643564\n",
      "P\n",
      "[[13 23]\n",
      " [16 23]]\n",
      "0.173333333333\n",
      "r\n",
      "[[ 5  7]\n",
      " [ 8 10]]\n",
      "0.166666666667\n",
      "R\n",
      "[[14  6]\n",
      " [12 12]]\n",
      "0.318181818182\n",
      "n\n",
      "[[17  4]\n",
      " [11  6]]\n",
      "0.447368421053\n",
      "N\n",
      "[[ 4 11]\n",
      " [ 4 12]]\n",
      "0.129032258065\n",
      "b\n",
      "[[6 3]\n",
      " [8 8]]\n",
      "0.24\n",
      "B\n",
      "[[ 5 11]\n",
      " [ 2 16]]\n",
      "0.147058823529\n",
      "q\n",
      "[[11 10]\n",
      " [ 6 11]]\n",
      "0.289473684211\n",
      "Q\n",
      "[[ 9  8]\n",
      " [ 7 10]]\n",
      "0.264705882353\n",
      "k\n",
      "[[2 9]\n",
      " [8 6]]\n",
      "0.08\n",
      "K\n",
      "[[3 7]\n",
      " [8 7]]\n",
      "0.12\n"
     ]
    }
   ],
   "source": [
    "def collect_results(test_df, predicted_y)\n",
    "    result_df = pd.DataFrame(columns=['training_instances', 'testingpct_white_moves',])\n",
    "    \n",
    "    #add predicted\n",
    "    length = all_test.shape[0]\n",
    "    test_df = all_test.set_index([range(0,length)])\n",
    "    test_df.loc[:,'predicted'] = y_pred\n",
    "    \n",
    "    #calculate overall confusion matrix\n",
    "    cm = confusion_matrx(test_df['y'], predicted_y)\n",
    "    \n",
    "    #calculate each piece confusion matrix\n",
    "    for p in \"pPrRnNbBqQkK\":\n",
    "        specific_piece = all_test[all_test['piece_moved'] == p]\n",
    "        cm = confusion_matrix(specific_piece['y'], specific_piece['predicted'])\n",
    "        test_df.loc[:, p + '_perf'] = cm\n",
    "#         print(cm)\n",
    "#         print(1.0 * cm[0][0] / (sum([sum(a) for a in cm])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
